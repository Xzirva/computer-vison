{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NST methods:\n",
    "Supervised learning: need a lot of paris and stylized\n",
    "NST (not supervised):\n",
    "Fast NSTm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with a pretrained model\n",
    "Use the model to extract the style 1\n",
    "and the content from the other (2)\n",
    "generate image to match both\n",
    "In a loop by minimizing the loss with respect of the style of (1) and the content of (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFeature Extractor from the content\\nFeature Extractor from the style\\nInit generated image with the content image\\n-> Computation of the content loss\\n-> The content loss might get larger because the inclusion of the style\\n-> Balancing game between the content loss and the style loss\\n\\nStyle loss: Comparing each layer of the feature extractor and the generator\\nStyle loss goes down and content loss get up (a little bit)\\nUsing gradients wrt. loss\\n\\nOne content and one style\\nBut takes time and a lot of iteration\\n\\nPerceptual Losses for RealTime Style Transfer (good results very fast on style transfer)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Extractor from the content\n",
    "Feature Extractor from the style\n",
    "Init generated image with the content image\n",
    "-> Computation of the content loss\n",
    "-> The content loss might get larger because the inclusion of the style\n",
    "-> Balancing game between the content loss and the style loss\n",
    "\n",
    "Style loss: Comparing each layer of the feature extractor and the generator\n",
    "Style loss goes down and content loss get up (a little bit)\n",
    "Using gradients wrt. loss\n",
    "\n",
    "One content and one style\n",
    "But takes time and a lot of iteration\n",
    "\n",
    "Perceptual Losses for RealTime Style Transfer (good results very fast on style transfer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How CNN see images:\n",
    "Low level features at the lower conv => Style\n",
    "High level features at the higher level (deeper) conv => Content\n",
    "\n",
    "19 = 16 conv + max and 3 fc layers\n",
    "\n",
    "2,2,4,4\n",
    "\n",
    "Taking the first  layers of each block to ge the style\n",
    "Layers for the content:\n",
    "- Experiment with different layers:\n",
    "Here we will choose the 3rd to last layer (block_5, conv_2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-env",
   "language": "python",
   "name": "cv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
