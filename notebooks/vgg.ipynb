{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/projects/computer-vision/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:10:43.104214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:10:44.795356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:44.798034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:44.798279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpus:\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "       tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "from utils import cv_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7f7d5e12da80>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "# Loading metadata\n",
    "wiki_metadata_df = scp.io.loadmat('/datasets/wiki/wiki.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = wiki_metadata_df['wiki'].dtype.fields.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = wiki_metadata_df['wiki'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = { col:metadata_df[i] for col, i in zip(metadata_columns, range(len(metadata_columns))) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328),\n",
       " (1, 62328)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ metadata_dict[c].shape for c in metadata_dict ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.DataFrame({ c:metadata_dict[c][0].tolist() for c in metadata_dict })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Sami Jauhojärvi]</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>[48/10000548_1925-04-04_1964.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Dettmar Cramer]</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Marc Okrand]</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>705061</td>\n",
       "      <td>1961</td>\n",
       "      <td>[65/10001965_1930-05-23_1961.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Aleksandar Matanović]</td>\n",
       "      <td>[[1, 1, 634, 440]]</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Diana Damrau]</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                          full_path  gender  \\\n",
       "0  723671         2009  [17/10000217_1981-05-05_2009.jpg]     1.0   \n",
       "1  703186         1964  [48/10000548_1925-04-04_1964.jpg]     1.0   \n",
       "2  711677         2008    [12/100012_1948-07-03_2008.jpg]     1.0   \n",
       "3  705061         1961  [65/10001965_1930-05-23_1961.jpg]     1.0   \n",
       "4  720044         2012  [16/10002116_1971-05-31_2012.jpg]     0.0   \n",
       "\n",
       "                     name                                      face_location  \\\n",
       "0       [Sami Jauhojärvi]  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1        [Dettmar Cramer]  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2           [Marc Okrand]      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "3  [Aleksandar Matanović]                                 [[1, 1, 634, 440]]   \n",
       "4          [Diana Damrau]  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "\n",
       "   face_score  second_face_score  \n",
       "0    4.300962                NaN  \n",
       "1    2.645639           1.949248  \n",
       "2    4.329329                NaN  \n",
       "3        -inf                NaN  \n",
       "4    3.408442                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['full_path'] = metadata_df['full_path'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR_ZERO_UNIX_EPOCH = 719529 # epoch of 1970-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/envs/cv-env/lib/python3.8/site-packages/numpy/lib/function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dob</th>\n",
       "      <td>62328.0</td>\n",
       "      <td>7.166810e+05</td>\n",
       "      <td>10832.627367</td>\n",
       "      <td>4077.000000</td>\n",
       "      <td>710673.000000</td>\n",
       "      <td>719269.000000</td>\n",
       "      <td>724702.250000</td>\n",
       "      <td>736011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>photo_taken</th>\n",
       "      <td>62328.0</td>\n",
       "      <td>1.998766e+03</td>\n",
       "      <td>20.907937</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>1992.750000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>59685.0</td>\n",
       "      <td>7.885231e-01</td>\n",
       "      <td>0.408359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face_score</th>\n",
       "      <td>62328.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.463949</td>\n",
       "      <td>3.760014</td>\n",
       "      <td>7.081268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_face_score</th>\n",
       "      <td>4096.0</td>\n",
       "      <td>2.009050e+00</td>\n",
       "      <td>0.981277</td>\n",
       "      <td>0.731419</td>\n",
       "      <td>1.164925</td>\n",
       "      <td>1.839065</td>\n",
       "      <td>2.655757</td>\n",
       "      <td>5.463147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count          mean           std          min  \\\n",
       "dob                62328.0  7.166810e+05  10832.627367  4077.000000   \n",
       "photo_taken        62328.0  1.998766e+03     20.907937  1940.000000   \n",
       "gender             59685.0  7.885231e-01      0.408359     0.000000   \n",
       "face_score         62328.0          -inf           NaN         -inf   \n",
       "second_face_score   4096.0  2.009050e+00      0.981277     0.731419   \n",
       "\n",
       "                             25%            50%            75%            max  \n",
       "dob                710673.000000  719269.000000  724702.250000  736011.000000  \n",
       "photo_taken          1992.750000    2009.000000    2012.000000    2015.000000  \n",
       "gender                  1.000000       1.000000       1.000000       1.000000  \n",
       "face_score                   NaN       2.463949       3.760014       7.081268  \n",
       "second_face_score       1.164925       1.839065       2.655757       5.463147  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62328,), (62328,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['dob'].dropna().shape, metadata_df['dob'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    47063\n",
       "0.0    12622\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['gender'].value_counts()\n",
    "# Oh only binary gender!? HOHO !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59685,), (62328,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['gender'].dropna().shape, metadata_df['gender'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = metadata_df.dropna(subset=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = metadata_df[metadata_df['face_score'].apply(np.isfinite)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['name'] = metadata_df['name'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sami Jauhojärvi</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>48/10000548_1925-04-04_1964.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dettmar Cramer</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marc Okrand</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Diana Damrau</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>716189</td>\n",
       "      <td>2012</td>\n",
       "      <td>02/10002702_1960-11-09_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Krista Tippett</td>\n",
       "      <td>[[274.76563240288175, 57.7700900839337, 376.88...</td>\n",
       "      <td>4.748056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                        full_path  gender  \\\n",
       "0  723671         2009  17/10000217_1981-05-05_2009.jpg     1.0   \n",
       "1  703186         1964  48/10000548_1925-04-04_1964.jpg     1.0   \n",
       "2  711677         2008    12/100012_1948-07-03_2008.jpg     1.0   \n",
       "4  720044         2012  16/10002116_1971-05-31_2012.jpg     0.0   \n",
       "5  716189         2012  02/10002702_1960-11-09_2012.jpg     0.0   \n",
       "\n",
       "              name                                      face_location  \\\n",
       "0  Sami Jauhojärvi  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1   Dettmar Cramer  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2      Marc Okrand      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "4     Diana Damrau  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "5   Krista Tippett  [[274.76563240288175, 57.7700900839337, 376.88...   \n",
       "\n",
       "   face_score  second_face_score  \n",
       "0    4.300962                NaN  \n",
       "1    2.645639           1.949248  \n",
       "2    4.329329                NaN  \n",
       "4    3.408442                NaN  \n",
       "5    4.748056                NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['gender'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will sample 10K females and 10k males images to balance out the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_matlab_to_datetime(d):\n",
    "    try:\n",
    "        return pd.to_datetime(d-YEAR_ZERO_UNIX_EPOCH, unit='D')\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['date_of_birth'] = metadata_df['dob'].apply(from_matlab_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1981-05-05\n",
       "Name: dob, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['dob'].iloc[:1].apply(from_matlab_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['date_of_birth'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['year_of_birth'] = metadata_df['date_of_birth'].apply(lambda x : x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['age'] = metadata_df['photo_taken'] - metadata_df['year_of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['age'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>723671</td>\n",
       "      <td>2009</td>\n",
       "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sami Jauhojärvi</td>\n",
       "      <td>[[111.29109473290997, 111.29109473290997, 252....</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981-05-05</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703186</td>\n",
       "      <td>1964</td>\n",
       "      <td>48/10000548_1925-04-04_1964.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dettmar Cramer</td>\n",
       "      <td>[[252.48330229530742, 126.68165114765371, 354....</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>1.949248</td>\n",
       "      <td>1925-04-04</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>711677</td>\n",
       "      <td>2008</td>\n",
       "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Marc Okrand</td>\n",
       "      <td>[[113.52, 169.83999999999997, 366.08, 422.4]]</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948-07-03</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720044</td>\n",
       "      <td>2012</td>\n",
       "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Diana Damrau</td>\n",
       "      <td>[[171.61031405173117, 75.57451239763239, 266.7...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971-05-31</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>716189</td>\n",
       "      <td>2012</td>\n",
       "      <td>02/10002702_1960-11-09_2012.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Krista Tippett</td>\n",
       "      <td>[[274.76563240288175, 57.7700900839337, 376.88...</td>\n",
       "      <td>4.748056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960-11-09</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                        full_path  gender  \\\n",
       "0  723671         2009  17/10000217_1981-05-05_2009.jpg     1.0   \n",
       "1  703186         1964  48/10000548_1925-04-04_1964.jpg     1.0   \n",
       "2  711677         2008    12/100012_1948-07-03_2008.jpg     1.0   \n",
       "4  720044         2012  16/10002116_1971-05-31_2012.jpg     0.0   \n",
       "5  716189         2012  02/10002702_1960-11-09_2012.jpg     0.0   \n",
       "\n",
       "              name                                      face_location  \\\n",
       "0  Sami Jauhojärvi  [[111.29109473290997, 111.29109473290997, 252....   \n",
       "1   Dettmar Cramer  [[252.48330229530742, 126.68165114765371, 354....   \n",
       "2      Marc Okrand      [[113.52, 169.83999999999997, 366.08, 422.4]]   \n",
       "4     Diana Damrau  [[171.61031405173117, 75.57451239763239, 266.7...   \n",
       "5   Krista Tippett  [[274.76563240288175, 57.7700900839337, 376.88...   \n",
       "\n",
       "   face_score  second_face_score date_of_birth  year_of_birth   age  \n",
       "0    4.300962                NaN    1981-05-05         1981.0  28.0  \n",
       "1    2.645639           1.949248    1925-04-04         1925.0  39.0  \n",
       "2    4.329329                NaN    1948-07-03         1948.0  60.0  \n",
       "4    3.408442                NaN    1971-05-31         1971.0  41.0  \n",
       "5    4.748056                NaN    1960-11-09         1960.0  52.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43452,), (43452,), (43452,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df['full_path'].dropna().shape,metadata_df['full_path'].shape, metadata_df['full_path'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.index = metadata_df['full_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_index = np.random.choice(metadata_df[metadata_df['gender'] == 0].index, SAMPLE_SIZE, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_index = np.random.choice(metadata_df[metadata_df['gender'] == 1].index, SAMPLE_SIZE, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([\n",
    "    metadata_df.loc[female_index],\n",
    "    metadata_df.loc[male_index]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65/23465465_1956-08-03_2007.jpg</th>\n",
       "      <td>714630</td>\n",
       "      <td>2007</td>\n",
       "      <td>65/23465465_1956-08-03_2007.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Susan Fernandez</td>\n",
       "      <td>[[169.83999999999997, 43.12, 295.6799999999999...</td>\n",
       "      <td>2.768081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956-08-03</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36/25824136_1988-03-05_2010.jpg</th>\n",
       "      <td>726167</td>\n",
       "      <td>2010</td>\n",
       "      <td>36/25824136_1988-03-05_2010.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kiersten Dallstream</td>\n",
       "      <td>[[239.6653855760832, 83.2722019227873, 312.786...</td>\n",
       "      <td>3.923385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-03-05</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11/15035211_1942-08-23_1967.jpg</th>\n",
       "      <td>709536</td>\n",
       "      <td>1967</td>\n",
       "      <td>11/15035211_1942-08-23_1967.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patricia McBride</td>\n",
       "      <td>[[151.78570352511005, 91.42342211506603, 286.7...</td>\n",
       "      <td>4.813193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1942-08-23</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87/22350387_1925-03-13_1949.jpg</th>\n",
       "      <td>703164</td>\n",
       "      <td>1949</td>\n",
       "      <td>87/22350387_1925-03-13_1949.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Susan Douglas Rubes</td>\n",
       "      <td>[[74.42411158725653, 147.96822317451307, 294.1...</td>\n",
       "      <td>3.691288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1925-03-13</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24/2410224_1950-01-29_1988.jpg</th>\n",
       "      <td>712252</td>\n",
       "      <td>1988</td>\n",
       "      <td>24/2410224_1950-01-29_1988.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ann Jillian</td>\n",
       "      <td>[[61.26358993209154, 101.76331655348591, 242.9...</td>\n",
       "      <td>3.314276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950-01-29</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    dob  photo_taken  \\\n",
       "full_path                                              \n",
       "65/23465465_1956-08-03_2007.jpg  714630         2007   \n",
       "36/25824136_1988-03-05_2010.jpg  726167         2010   \n",
       "11/15035211_1942-08-23_1967.jpg  709536         1967   \n",
       "87/22350387_1925-03-13_1949.jpg  703164         1949   \n",
       "24/2410224_1950-01-29_1988.jpg   712252         1988   \n",
       "\n",
       "                                                       full_path  gender  \\\n",
       "full_path                                                                  \n",
       "65/23465465_1956-08-03_2007.jpg  65/23465465_1956-08-03_2007.jpg     0.0   \n",
       "36/25824136_1988-03-05_2010.jpg  36/25824136_1988-03-05_2010.jpg     0.0   \n",
       "11/15035211_1942-08-23_1967.jpg  11/15035211_1942-08-23_1967.jpg     0.0   \n",
       "87/22350387_1925-03-13_1949.jpg  87/22350387_1925-03-13_1949.jpg     0.0   \n",
       "24/2410224_1950-01-29_1988.jpg    24/2410224_1950-01-29_1988.jpg     0.0   \n",
       "\n",
       "                                                name  \\\n",
       "full_path                                              \n",
       "65/23465465_1956-08-03_2007.jpg      Susan Fernandez   \n",
       "36/25824136_1988-03-05_2010.jpg  Kiersten Dallstream   \n",
       "11/15035211_1942-08-23_1967.jpg     Patricia McBride   \n",
       "87/22350387_1925-03-13_1949.jpg  Susan Douglas Rubes   \n",
       "24/2410224_1950-01-29_1988.jpg           Ann Jillian   \n",
       "\n",
       "                                                                     face_location  \\\n",
       "full_path                                                                            \n",
       "65/23465465_1956-08-03_2007.jpg  [[169.83999999999997, 43.12, 295.6799999999999...   \n",
       "36/25824136_1988-03-05_2010.jpg  [[239.6653855760832, 83.2722019227873, 312.786...   \n",
       "11/15035211_1942-08-23_1967.jpg  [[151.78570352511005, 91.42342211506603, 286.7...   \n",
       "87/22350387_1925-03-13_1949.jpg  [[74.42411158725653, 147.96822317451307, 294.1...   \n",
       "24/2410224_1950-01-29_1988.jpg   [[61.26358993209154, 101.76331655348591, 242.9...   \n",
       "\n",
       "                                 face_score  second_face_score date_of_birth  \\\n",
       "full_path                                                                      \n",
       "65/23465465_1956-08-03_2007.jpg    2.768081                NaN    1956-08-03   \n",
       "36/25824136_1988-03-05_2010.jpg    3.923385                NaN    1988-03-05   \n",
       "11/15035211_1942-08-23_1967.jpg    4.813193                NaN    1942-08-23   \n",
       "87/22350387_1925-03-13_1949.jpg    3.691288                NaN    1925-03-13   \n",
       "24/2410224_1950-01-29_1988.jpg     3.314276                NaN    1950-01-29   \n",
       "\n",
       "                                 year_of_birth   age  \n",
       "full_path                                             \n",
       "65/23465465_1956-08-03_2007.jpg         1956.0  51.0  \n",
       "36/25824136_1988-03-05_2010.jpg         1988.0  22.0  \n",
       "11/15035211_1942-08-23_1967.jpg         1942.0  25.0  \n",
       "87/22350387_1925-03-13_1949.jpg         1925.0  24.0  \n",
       "24/2410224_1950-01-29_1988.jpg          1950.0  38.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (2, 28, 28, 3)\n",
    "x = np.arange(np.prod(input_shape)).reshape(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 28, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ (t, b), (l, r) for t, l, b, r in tdataset['face_location'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['crop_coords'] = dataset['face_location'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jpg    16000\n",
       "Name: full_path, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['full_path'].apply(lambda x: x[-3:]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have image of format `jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_PATH = \"/datasets/wiki/images/\"\n",
    "ROOT_PATH = \"/datasets/wiki_crop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = tf.keras.preprocessing.image_dataset_from_directory(ROOT_PATH, interpolation='gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:10:55.110414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 17:10:55.111216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.111462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.111692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.624727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.624975: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.624988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-30 17:10:55.625179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-30 17:10:55.625216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5898 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tf_dataset_df = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        tf.cast(dataset['full_path'], tf.string),\n",
    "        # tf.cast(dataset['crop_coords'], tf.int32),\n",
    "        tf.cast(dataset['age'], tf.int32),\n",
    "        tf.cast(dataset['gender'], tf.int32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'65/23465465_1956-08-03_2007.jpg', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for f, a, d in tf_dataset_df.take(1):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the path as key in this dataset\n",
    "def decode_img(img):\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "def preprocess_data(path, age, label):\n",
    "    img = tf.io.read_file(ROOT_PATH + path)\n",
    "    img = decode_img(img)\n",
    "    return img, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 0.8, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size = len(tf_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset_df = tf_dataset_df.shuffle(buffer_size=df_size)\n",
    "train_df = tf_dataset_df.take(round(TRAIN_SIZE * df_size))\n",
    "test_df = tf_dataset_df.skip(round(TRAIN_SIZE * df_size))\n",
    "val_df = test_df.take(round(VAL_SIZE * df_size))\n",
    "test_df = test_df.skip(round(VAL_SIZE * df_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "STANDARD_BATCH_SIZE, STANDARD_PREFETCH_BUFFER = 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'76/2431776_1982-01-28_2014.jpg', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for f, a, d in train_df.take(1):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "test_df = test_df.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "val_df = val_df.map(preprocess_data, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch_load(tf_df, batch_size=STANDARD_BATCH_SIZE, prefetch_buffer=STANDARD_PREFETCH_BUFFER):\n",
    "    tf_df = tf_df.shuffle(buffer_size=(len(tf_df)))\n",
    "    tf_df = tf_df.batch(batch_size)\n",
    "    tf_df = tf_df.prefetch(buffer_size=prefetch_buffer)\n",
    "    return tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_batch_load(train_df)\n",
    "val_df = prepare_batch_load(val_df)\n",
    "test_df = prepare_batch_load(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvModel(K.Model):\n",
    "    def __init__(self, filters, kernel_size, strides, pool_size, activation, n_units=1):\n",
    "        super(SimpleConvModel, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.norm = K.layers.Rescaling(1./255)\n",
    "        # Defining the layers\n",
    "        self.conv2D_0 = K.layers.Conv2D(\n",
    "            name='conv2D_0', \n",
    "            filters=self.filters, kernel_size=self.kernel_size, activation='relu', padding='same'\n",
    "        )\n",
    "\n",
    "        self.max_pool = K.layers.MaxPool2D(\n",
    "            name='max_pool_0',\n",
    "            pool_size=pool_size, strides=strides\n",
    "        )\n",
    "\n",
    "        self.flatten = K.layers.Flatten()\n",
    "\n",
    "        self.dense_0 = K.layers.Dense(units=32, activation='relu', name='dense_0')\n",
    "        self.predictor = K.layers.Dense(units=n_units, activation=K.activations.get(activation), name='age_predictor')\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        x = self.norm(inputs)\n",
    "        x = self.conv2D_0(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_0(x)\n",
    "        x = self.predictor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = SimpleConvModel(filters=64, kernel_size=3, strides=1, pool_size=2, activation='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(\n",
    "    optimizer='adam', loss='mse', metrics=['mape', 'mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ c[0].numpy() for c in train_df.take(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:53:50.003580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-11-30 16:53:51.057232: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1ea0e9f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-30 16:53:51.057294: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2022-11-30 16:53:51.062026: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-30 16:53:51.174693: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158/3200 [============================>.] - ETA: 0s - loss: 622.3773 - mape: 43.6536 - mae: 14.5364"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m simple_model\u001b[39m.\u001b[39;49mfit(train_df, validation_data\u001b[39m=\u001b[39;49mval_df, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simple_model.fit(train_df, validation_data=val_df, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:18:28.016614: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-11-30 14:18:28.016706: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: cHRM chunk does not match sRGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 2s 8ms/step - loss: 898.7798 - mape: 63.5435 - mae: 25.1694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[898.77978515625, 63.54345703125, 25.169401168823242]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(K.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, strides=2, pool_size=2):\n",
    "        super(VGGBlock, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        # self.norm = K.layers.Rescaling(1./255)\n",
    "\n",
    "\n",
    "        self.repetitions = repetitions\n",
    "\n",
    "        for rep in range(self.repetitions):\n",
    "            vars(self)[f'conv2D_{rep}'] = K.layers.Conv2D(\n",
    "                filters=filters, kernel_size=kernel_size, activation='relu', padding='same'\n",
    "            )\n",
    "\n",
    "        # Defining the layers\n",
    "        # self.conv2D_0 = K.layers.Conv2D(\n",
    "        #     name='conv2D_0', \n",
    "        #     filters=self.filters, kernel_size=self.kernel_size, activation='relu', padding='same'\n",
    "        # )\n",
    "\n",
    "        self.max_pool = K.layers.MaxPool2D(\n",
    "            pool_size=pool_size, strides=strides\n",
    "        )\n",
    "        \n",
    "    def __call__(self, inputs, training=True):\n",
    "        x = self.conv2D_0(inputs)\n",
    "        x = self.max_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(K.Model):\n",
    "    def __init__(self, activation):\n",
    "        super(VGG, self).__init__()\n",
    "        self.activation = K.activations.get(activation)\n",
    "        self.norm = K.layers.Rescaling(1./255)\n",
    "        self.block_0 = VGGBlock(64, 3, 2)\n",
    "        self.block_1 = VGGBlock(128, 3, 2)\n",
    "        self.block_2 = VGGBlock(256, 3, 3)\n",
    "        self.block_3 = VGGBlock(512, 3, 3)\n",
    "        self.block_4 = VGGBlock(512, 3, 3)\n",
    "        self.flatten = K.layers.Flatten()\n",
    "        self.dense = K.layers.Dense(units=4096, activation='relu')\n",
    "        self.predictor = K.layers.Dense(units=1, activation=self.activation)\n",
    "\n",
    "    def __call__(self, inputs, training=True):\n",
    "        x = self.norm(inputs)\n",
    "        x = self.block_0(x)\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.predictor(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(\n",
    "    optimizer='adam', loss='mse', metrics=['mae', 'mape']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:11:47.360276: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 7416 of 12800\n",
      "2022-11-30 17:11:54.747772: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2022-11-30 17:11:55.341778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-11-30 17:11:56.748096: W tensorflow/tsl/framework/bfc_allocator.cc:360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2022-11-30 17:11:57.104783: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1f3ca680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-30 17:11:57.104835: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n",
      "2022-11-30 17:11:57.110269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-11-30 17:11:57.217645: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 123s 40ms/step - loss: 360287962136576.0000 - mae: 167774.2812 - mape: 6438675.0000 - val_loss: 238.8466 - val_mae: 11.9667 - val_mape: 26456886.0000\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:13:50.066028: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 10841 of 12800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/2560 [..............................] - ETA: 1:28 - loss: 203.0317 - mae: 11.6412 - mape: 27.5319  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:13:51.897021: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 118s 41ms/step - loss: 360287962136576.0000 - mae: 167774.6406 - mape: 5723222.5000 - val_loss: 244.2556 - val_mae: 11.9323 - val_mape: 34.6041\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:15:47.643630: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 12329 of 12800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5/2560 [..............................] - ETA: 1:27 - loss: 88.9832 - mae: 8.3798 - mape: 28.5430 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:15:48.036950: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 109s 39ms/step - loss: 360287962136576.0000 - mae: 167783.2031 - mape: 4728774.5000 - val_loss: 270.3767 - val_mae: 12.9088 - val_mape: 25072536.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:17:37.088246: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 12595 of 12800\n",
      "2022-11-30 17:17:37.251903: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 110s 39ms/step - loss: 360287962136576.0000 - mae: 167791.7344 - mape: 3061576.2500 - val_loss: 712.0352 - val_mae: 20.8333 - val_mape: 64.6326\n",
      "Epoch 5/10\n",
      "2560/2560 [==============================] - 110s 39ms/step - loss: 360287962136576.0000 - mae: 167811.5625 - mape: 11008714.0000 - val_loss: 1854.8348 - val_mae: 34.0012 - val_mape: 101.1152\n",
      "Epoch 6/10\n",
      "2560/2560 [==============================] - 119s 43ms/step - loss: 360287928582144.0000 - mae: 167871.0781 - mape: 11860108.0000 - val_loss: 13576.5312 - val_mae: 92.7201 - val_mape: 277.8386\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 17:23:16.639183: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 12665 of 12800\n",
      "2022-11-30 17:23:16.749523: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 183/2560 [=>............................] - ETA: 1:39 - loss: 12092.6641 - mae: 88.0639 - mape: 267.5892"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vgg_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     train_df,\n\u001b[1;32m      3\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_df,\n\u001b[1;32m      4\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1655\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1656\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1658\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 476\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    322\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    326\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 346\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    349\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    393\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 394\u001b[0m     hook(batch, logs)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1169\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    663\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 665\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    656\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    659\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    660\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \n\u001b[1;32m   1134\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1120\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1122\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg_model.fit(\n",
    "    train_df,\n",
    "    validation_data=val_df,\n",
    "    epochs = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vgg_model\u001b[39m.\u001b[39mevaluate(train_df)\n\u001b[1;32m      2\u001b[0m vgg_model\u001b[39m.\u001b[39mevaluate(val_df)\n\u001b[1;32m      3\u001b[0m vgg_model\u001b[39m.\u001b[39mevaluate(test_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg_model' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_model.evaluate(train_df)\n",
    "vgg_model.evaluate(val_df)\n",
    "vgg_model.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:59:39.016692: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-11-30 14:59:39.181689: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-11-30 14:59:39.235726: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-11-30 14:59:39.435401: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 746ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:59:39.514409: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38.877346],\n",
       "       [30.025137],\n",
       "       [36.559353],\n",
       "       [35.593525],\n",
       "       [36.950672]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.predict(val_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:59:23.091790: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n",
      "2022-11-30 14:59:23.173410: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: profile 'icc': 'RGB ': RGB color space not permitted on grayscale PNG\n",
      "2022-11-30 14:59:23.559055: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n",
      "2022-11-30 14:59:23.587835: W tensorflow/core/lib/png/png_io.cc:88] PNG warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(5, 256, 256, 3), dtype=float32, numpy=\n",
       "  array([[[[254.       , 255.       , 249.71289  ],\n",
       "           [253.92516  , 255.       , 249.81383  ],\n",
       "           [253.40599  , 255.       , 250.203    ],\n",
       "           ...,\n",
       "           [251.2517   , 245.82591  , 159.95651  ],\n",
       "           [252.42282  , 248.17218  , 160.12234  ],\n",
       "           [253.51562  , 250.0562   , 161.63042  ]],\n",
       "  \n",
       "          [[253.94952  , 254.13867  , 244.7943   ],\n",
       "           [253.31445  , 254.29007  , 246.91898  ],\n",
       "           [254.05742  , 255.       , 249.48906  ],\n",
       "           ...,\n",
       "           [248.75508  , 244.75508  , 157.75508  ],\n",
       "           [252.61133  , 250.03117  , 164.45102  ],\n",
       "           [254.89093  , 254.4964   , 169.21906  ]],\n",
       "  \n",
       "          [[253.16199  , 255.       , 238.93945  ],\n",
       "           [253.6707   , 255.       , 241.44882  ],\n",
       "           [253.56445  , 255.       , 245.10025  ],\n",
       "           ...,\n",
       "           [245.36978  , 243.24219  , 159.36848  ],\n",
       "           [249.9379   , 248.76212  , 165.92265  ],\n",
       "           [253.51003  , 253.74011  , 170.76562  ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[208.74023  , 221.62305  , 229.50586  ],\n",
       "           [213.9715   , 223.71835  , 229.61914  ],\n",
       "           [219.99869  , 221.23306  , 225.20377  ],\n",
       "           ...,\n",
       "           [242.79819  , 231.11655  , 214.08073  ],\n",
       "           [205.7039   , 201.99101  , 196.49297  ],\n",
       "           [195.92552  , 197.50586  , 200.94128  ]],\n",
       "  \n",
       "          [[211.76852  , 226.00063  , 234.6943   ],\n",
       "           [213.26562  , 223.26375  , 228.7364   ],\n",
       "           [220.04297  , 220.52734  , 221.76953  ],\n",
       "           ...,\n",
       "           [238.54337  , 228.90665  , 210.85587  ],\n",
       "           [200.81836  , 203.93758  , 196.06546  ],\n",
       "           [191.05336  , 201.42938  , 199.86719  ]],\n",
       "  \n",
       "          [[212.56792  , 227.23663  , 235.79057  ],\n",
       "           [217.96515  , 227.83203  , 233.43     ],\n",
       "           [221.1444   , 219.69894  , 221.65402  ],\n",
       "           ...,\n",
       "           [239.44753  , 229.8108   , 211.76003  ],\n",
       "           [202.98016  , 207.51923  , 198.9372   ],\n",
       "           [192.38986  , 206.92111  , 203.68674  ]]],\n",
       "  \n",
       "  \n",
       "         [[[108.1037   , 110.22656  ,  75.83984  ],\n",
       "           [ 90.7475   ,  96.10968  ,  61.64734  ],\n",
       "           [ 67.36224  ,  74.97266  ,  41.838806 ],\n",
       "           ...,\n",
       "           [120.00287  , 121.82214  ,  85.33307  ],\n",
       "           [120.5025   , 121.5025   ,  88.35547  ],\n",
       "           [121.       , 122.       ,  90.83417  ]],\n",
       "  \n",
       "          [[106.218445 , 105.14453  ,  69.5025   ],\n",
       "           [100.92761  , 101.53699  ,  67.97449  ],\n",
       "           [ 81.818726 ,  84.86719  ,  53.874207 ],\n",
       "           ...,\n",
       "           [116.53516  , 118.53516  ,  81.48828  ],\n",
       "           [119.78125  , 121.390625 ,  86.34375  ],\n",
       "           [122.15485  , 123.15485  ,  91.15485  ]],\n",
       "  \n",
       "          [[109.01483  , 111.79791  ,  73.006775 ],\n",
       "           [107.760925 , 112.05701  ,  75.94763  ],\n",
       "           [ 88.05206  ,  94.2005   ,  60.016907 ],\n",
       "           ...,\n",
       "           [116.96875  , 118.97003  ,  79.86981  ],\n",
       "           [122.00311  , 123.22186  ,  86.51251  ],\n",
       "           [126.65912  , 126.65912  ,  90.65912  ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 39.472656 ,  52.472656 ,  34.308594 ],\n",
       "           [ 35.303894 ,  47.13513  ,  29.530457 ],\n",
       "           [ 31.065125 ,  42.065125 ,  25.983093 ],\n",
       "           ...,\n",
       "           [139.80334  , 120.85022  , 122.865845 ],\n",
       "           [133.90546  , 111.174194 , 112.24298  ],\n",
       "           [121.75183  ,  96.15808  ,  95.361206 ]],\n",
       "  \n",
       "          [[ 38.33734  ,  49.23578  ,  36.888123 ],\n",
       "           [ 36.76593  ,  47.390625 ,  35.04297  ],\n",
       "           [ 36.606262 ,  47.017212 ,  34.676575 ],\n",
       "           ...,\n",
       "           [132.96954  , 114.01642  , 118.00079  ],\n",
       "           [128.3089   , 107.918274 , 108.137024 ],\n",
       "           [113.34625  ,  89.95563  ,  88.15875  ]],\n",
       "  \n",
       "          [[ 35.59375  ,  48.777344 ,  27.859375 ],\n",
       "           [ 34.       ,  46.46234  ,  25.880005 ],\n",
       "           [ 35.03125  ,  46.211975 ,  28.321106 ],\n",
       "           ...,\n",
       "           [134.15338  , 120.19037  , 120.21301  ],\n",
       "           [133.75641  , 114.72797  , 112.265625 ],\n",
       "           [121.60333  , 100.67792  ,  96.046875 ]]],\n",
       "  \n",
       "  \n",
       "         [[[235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           ...,\n",
       "           [121.59375  , 104.       ,  68.40625  ],\n",
       "           [110.78125  ,  96.625    ,  67.234375 ],\n",
       "           [170.19531  , 163.83594  , 140.39844  ]],\n",
       "  \n",
       "          [[235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           ...,\n",
       "           [120.99219  , 103.39844  ,  67.80469  ],\n",
       "           [110.703125 ,  96.546875 ,  67.15625  ],\n",
       "           [172.97656  , 165.79688  , 144.82031  ]],\n",
       "  \n",
       "          [[235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           [235.       , 235.       , 233.       ],\n",
       "           ...,\n",
       "           [120.28906  , 102.69531  ,  67.203125 ],\n",
       "           [110.125    ,  95.96875  ,  68.46094  ],\n",
       "           [177.07812  , 169.71875  , 151.28125  ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 68.       ,  64.       ,  65.       ],\n",
       "           [ 68.578125 ,  64.578125 ,  65.578125 ],\n",
       "           [ 69.10156  ,  65.10156  ,  66.10156  ],\n",
       "           ...,\n",
       "           [176.       , 162.       , 136.       ],\n",
       "           [176.46094  , 162.46094  , 136.46094  ],\n",
       "           [177.       , 163.       , 137.       ]],\n",
       "  \n",
       "          [[ 67.53906  ,  63.539062 ,  64.53906  ],\n",
       "           [ 69.96094  ,  65.96094  ,  66.96094  ],\n",
       "           [ 68.30469  ,  64.30469  ,  65.30469  ],\n",
       "           ...,\n",
       "           [177.       , 163.       , 137.       ],\n",
       "           [177.       , 163.       , 137.       ],\n",
       "           [177.5      , 163.5      , 137.5      ]],\n",
       "  \n",
       "          [[ 65.21875  ,  61.21875  ,  62.21875  ],\n",
       "           [ 67.38281  ,  63.382812 ,  64.38281  ],\n",
       "           [ 63.609375 ,  59.609375 ,  60.609375 ],\n",
       "           ...,\n",
       "           [177.10156  , 163.10156  , 137.10156  ],\n",
       "           [177.96094  , 163.96094  , 137.96094  ],\n",
       "           [178.       , 164.       , 138.       ]]],\n",
       "  \n",
       "  \n",
       "         [[[ 11.28125  ,  59.       ,  40.640625 ],\n",
       "           [ 10.       ,  59.       ,  40.       ],\n",
       "           [ 10.796875 ,  58.203125 ,  40.       ],\n",
       "           ...,\n",
       "           [  5.796875 ,  41.796875 ,  29.796875 ],\n",
       "           [  4.078125 ,  40.078125 ,  28.078125 ],\n",
       "           [  2.359375 ,  38.359375 ,  26.359375 ]],\n",
       "  \n",
       "          [[ 13.490997 ,  58.303925 ,  41.       ],\n",
       "           [ 11.154297 ,  58.154297 ,  40.154297 ],\n",
       "           [ 11.4002075,  58.03134  ,  40.154297 ],\n",
       "           ...,\n",
       "           [  5.642578 ,  41.64258  ,  29.642578 ],\n",
       "           [  3.1441956,  39.144196 ,  27.144196 ],\n",
       "           [  2.359375 ,  38.359375 ,  26.359375 ]],\n",
       "  \n",
       "          [[ 16.15628  ,  58.       ,  41.591827 ],\n",
       "           [ 13.847656 ,  58.07617  ,  41.       ],\n",
       "           [ 13.969055 ,  58.015472 ,  41.       ],\n",
       "           ...,\n",
       "           [  4.796875 ,  40.796875 ,  28.796875 ],\n",
       "           [  3.078125 ,  39.078125 ,  27.078125 ],\n",
       "           [  2.9512024,  38.951202 ,  26.951202 ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 20.744415 ,  46.79715  ,  28.107788 ],\n",
       "           [ 28.884766 ,  49.26767  ,  32.786926 ],\n",
       "           [ 96.64197  , 108.25134  ,  91.870636 ],\n",
       "           ...,\n",
       "           [ 14.609375 ,  45.       ,  30.203125 ],\n",
       "           [ 17.       ,  45.       ,  31.       ],\n",
       "           [ 15.359375 ,  42.078125 ,  28.71875  ]],\n",
       "  \n",
       "          [[ 15.649567 ,  38.626892 ,  26.546051 ],\n",
       "           [ 63.85904  ,  80.98532  ,  72.42215  ],\n",
       "           [122.711975 , 133.47565  , 124.75299  ],\n",
       "           ...,\n",
       "           [ 14.609375 ,  45.       ,  30.203125 ],\n",
       "           [ 17.       ,  45.       ,  31.       ],\n",
       "           [ 15.359375 ,  42.078125 ,  28.71875  ]],\n",
       "  \n",
       "          [[100.751495 , 120.24448  , 116.73547  ],\n",
       "           [140.62311  , 155.1282   , 155.37668  ],\n",
       "           [167.86899  , 176.86313  , 177.50772  ],\n",
       "           ...,\n",
       "           [ 14.609375 ,  45.       ,  30.203125 ],\n",
       "           [ 17.       ,  45.       ,  31.       ],\n",
       "           [ 15.359375 ,  42.078125 ,  28.71875  ]]],\n",
       "  \n",
       "  \n",
       "         [[[ 32.48065  ,  32.48065  ,  32.48065  ],\n",
       "           [ 32.423523 ,  32.423523 ,  32.423523 ],\n",
       "           [ 32.535156 ,  32.535156 ,  32.535156 ],\n",
       "           ...,\n",
       "           [ 42.528503 ,  42.528503 ,  42.528503 ],\n",
       "           [ 40.90625  ,  40.90625  ,  40.90625  ],\n",
       "           [ 41.76172  ,  41.76172  ,  41.76172  ]],\n",
       "  \n",
       "          [[ 29.233276 ,  29.233276 ,  29.233276 ],\n",
       "           [ 34.78351  ,  34.78351  ,  34.78351  ],\n",
       "           [ 36.41913  ,  36.41913  ,  36.41913  ],\n",
       "           ...,\n",
       "           [ 37.433594 ,  37.433594 ,  37.433594 ],\n",
       "           [ 36.748352 ,  36.748352 ,  36.748352 ],\n",
       "           [ 37.839294 ,  37.839294 ,  37.839294 ]],\n",
       "  \n",
       "          [[ 32.17578  ,  32.17578  ,  32.17578  ],\n",
       "           [ 29.921875 ,  29.921875 ,  29.921875 ],\n",
       "           [ 29.       ,  29.       ,  29.       ],\n",
       "           ...,\n",
       "           [ 37.496765 ,  37.496765 ,  37.496765 ],\n",
       "           [ 38.420715 ,  38.420715 ,  38.420715 ],\n",
       "           [ 44.043884 ,  44.043884 ,  44.043884 ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[241.38672  , 241.38672  , 241.38672  ],\n",
       "           [234.76562  , 234.76562  , 234.76562  ],\n",
       "           [231.20312  , 231.20312  , 231.20312  ],\n",
       "           ...,\n",
       "           [240.       , 240.       , 240.       ],\n",
       "           [239.57147  , 239.57147  , 239.57147  ],\n",
       "           [239.53516  , 239.53516  , 239.53516  ]],\n",
       "  \n",
       "          [[245.32031  , 245.32031  , 245.32031  ],\n",
       "           [236.57587  , 236.57587  , 236.57587  ],\n",
       "           [232.20312  , 232.20312  , 232.20312  ],\n",
       "           ...,\n",
       "           [240.8789   , 240.8789   , 240.8789   ],\n",
       "           [240.8789   , 240.8789   , 240.8789   ],\n",
       "           [240.75781  , 240.75781  , 240.75781  ]],\n",
       "  \n",
       "          [[245.71875  , 245.71875  , 245.71875  ],\n",
       "           [239.60938  , 239.60938  , 239.60938  ],\n",
       "           [237.39062  , 237.39062  , 237.39062  ],\n",
       "           ...,\n",
       "           [245.       , 245.       , 245.       ],\n",
       "           [242.23438  , 242.23438  , 242.23438  ],\n",
       "           [243.28125  , 243.28125  , 243.28125  ]]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(5,), dtype=int8, numpy=array([27, 32, 29, 31, 28], dtype=int8)>)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Regularization in a NN\n",
    "# J(wi, bi, ...) = 1 / m sum(loss(y_hat_i, y_i)) + [ L2normReg(w[l]) for l in layers ],  \n",
    "# Frobenius norm (not called L2 for maths reason (linear algrebra)),   \n",
    "# dw gets a new term = lambda / m.  \n",
    "# Weight Decay: Multiplying the weight matrix by a (1 -alpha * lambda / 2m)y\n",
    "\n",
    "# the term lambda forces W close to zero which makes some neurons have a smaller effect in the prediction. L1 norm would actually make them zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('cv-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88de0083f64d3083508852baa7dae69acbad25dc7a9be700ce04fff49d0b1750"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
